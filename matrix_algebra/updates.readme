5/18/2024 updates :(compression & more cache utilization updates)
1-Added an enumeration for different types of matrices: general, upper triangular (utri),
  lower triangular (ltri), diagonal, symmetric, anti-symmetric, constant, identity (iden),
  and orthonormal.

2-Added two integer pointers row_start and pindex for mapping upper and lower triangular matrices.
  row_start maps the start of each row into the vector since upper and lower triangular matrices 
  are stored without zeroes. pindex stores the locations of pivots.

3-Added a boolean is_compressed to ensure a compressed matrix is not compressed again.

4-Added an integer actual_size to store the actual size allocated for the matrix.

5-Added a mutable array empty_vec of one element. For upper triangular matrices, it returns 0. 
  It allows for compression of anti-symmetric matrices since the lower part is the negative of 
  the upper part. For mutable, the idea is to store in empty_vec the value at the upper part 
  multiplied by -1 and return the value so it can be both used in constant and non-constant matrices.

6-Added a mutable integer matrix_type to store the type of the matrix: general, orthonormal, 
upper triangular, etc.

7-Added a function set_feature that fills matrix_type and sets at_ptr and at_ptr_c.

8-Added a function set_at_ptr that sets at_ptr and at_ptr_c according to matrix_type.

9-Added function pointers at_ptr and at_ptr_c that store the address of at. 
  There are 8 at functions, one for each type of matrix. 
  Each accesses the data according to the matrix type, 
  so at_ptr is put inside the original at that's accessible to the user and inside it, 
  it calls the specific accessor according to the matrix type using the pointer.

10-Added compression functions for each matrix type: compress_utri, compress_ltri, 
compress_symmetric, compress_anti_symmetric, compress_diagonal, compress_identity, 
and compress_const. These functions compress the respective types of matrices.

11-If a function returns a matrix with special features (like gauss_down, gauss_up, get_pivots,
gram_shmidt), the matrix is compressed or matrix type if the matrix isn't compressible. 
For example, if it's orthonormal, then the transpose is returned instead of performing 
Gauss-Jordan elimination.

12-Matrices performing operations on compressed matrices (for example, if you multiply a compressed 
  matrix by a non-compressed one) do not cause problems. The code has been thoroughly tested and
  adjusted to ensure stability.

13-Added at functions for each matrix type. These functions are used to access elements 
  in the matrix according to its type. Compressed matrices like upper triangular,
  lower triangular, symmetric, anti-symmetric are stored in row-major order. For diagonal matrices,
  only the main diagonal is stored. For constant matrices, only one element is stored. 
  For identity matrices, only a 1 is stored.

14-The at functions for each matrix type are: at_general, at_utri, at_ltri, at_diagonal, 
  at_identity, at_const, at_symmetric, at_anti_symmetric. Each of these functions takes 
  two integer parameters (presumably for the row and column indices) and returns a reference 
  to a DataType.

15-Added at functions for each matrix type for matrices that are constant and just used in 
  calculations. These functions are: at_general_c, at_utri_c, at_ltri_c, at_diagonal_c, at_identity_c,
  at_const_c, at_symmetric_c, at_anti_symmetric_c.
  Each of these functions takes two integer parameters (presumably for the row and column indices) 
  and returns a constant reference to a DataType.
  
16-Added a compress function. This function compresses the matrix. It doesn't require 
  any parameters. It uses the fill_features function to analyze the matrix for special features, 
  fills the matrix_type with the feature, and compresses it accordingly.

17-Added a decompress function. This function decompresses the matrix. It doesn't require 
any parameters.

18-Added a fill_features function. This function analyzes the matrix for special features and 
  fills matrix_type. It takes an optional parameter check_tol which defaults to 1e-6. 
  This parameter is presumably used as a tolerance for checking the features of the matrix.


5/6/2024 update:
fixed transformer Now it works as intended; it worked only when producing the inverse, but now it works on any transformation.

The idea is simple: get a system that converts a to b, so if a enters that system, it turns into b. 
Now it's working. 
5/5/2024 update:
-added transformer, which returns the linear transformation matrix that turns an input into an output.
Both must be on a on a full basis, so if you pass a matrix with independent columns as an input to that system and the output is
the identity, then the system is the inverse of that matrix. Check the comments on the function; it's pretty simple. 
actually.

5/3/2024 updates:
-added operator, which calculates the powers of a matrix (A^K).
Sadly, the results are dependent on the QR algorithm to get the eigenvalues, so the results aren't quite correct.
-added SVD (singal value decomposition), which again relies on the iteration algorithm to get the eigen values
If the eigen values are correct, the results for both power and SVD are perfectly fine, but due to the nature of the
Iteration algorithm is the best I can do. 
If you have any suggestions, please let me know. 
5/2/2024 updates:
1. Fixed percision errors that lead to the wrong output of gram_shmidt 
using two tolerance values 
  tolerance that is used in calculations like inverse, gram-shmidt, gauge_down,gauss_down....etc
  This is sufficient for gram-shmidt since it requires a high degree of precision.
const double tolerance = 1e-12; better not to be changed 
  Check_tolerance is for is_identity, is_zero, aka every function starting with is_
except for is_pivot since it is used in calculations.
  Modify this the way you want.
const double check_tolerance =1e-6;
  Both consants are found in the complex.h file.

added eigne_values, which calculates eigen values via an iteration method using 
QR factorization returns the eigenvalues of a matrix in a column matrix.
computations made by QR factorization
doesn't generate correct results all the time due to divergence issues and the nature of the 
numerical method itself

-removed filterization from constructors where an element is less than a specified tolerance 
It was replaced with zero and added in-place filter functions that filter the caller's elements. 
These changes had to be made due to the gram-shmidt process requiring a lot of precision.
tested the function on a 100,000 randomly generated matrix, and it's stable now.

-added qr_fact(matrix q, matrix r), which performs qr factorization and puts the 
residues in the q and r inputmatrices
have fun!

-added rand, which creates a randomly generated matrix at specified dimensions.

5/1/2024:
Important notes:
When using gram_shmidt, it's better to use it with a double and with a very low tolerance value, very close to zero.
I've noticed this a lot when testing the algorithm. 
fixed a small issue in the inverse where if a row is switched during the pivoting, the return matrix 
or the inverse matrix didn't record that. 
4/30/2024, small update:
optimized some functions. 
added get_pivots,is_positive_definite 
4/29/2024, small update:
added resize, which takes 3 parameters: row size, column size, and padding value (by default, zero).
and returns the wanted matrix with the new dimensions I've integerated into the fft, but the 
Results aren't correct when tested next to Matlab results, though the padding is correct and the fft is correct. 
It just doesn't make any sense for me. If you have suggestions, please let me know. Maybe I misunderstood the padding concept.
but the fft works fine when passing matrices with a row value that is a power of 2. 
4/28/2024, great news:
FFT is officially added to the library and 
I've put it through a lot of tests with the normal Fourier transform.
(aka the fourier matrix multiplied by the data set) 

also updated the complex class to work with double instead of float because of the tolerance issue.

I didn't add a padding function to make the algorithm work with non-powers of 2. 
maybe later.

Note: The fft/fourier_mat is clockwise, not counterclockwise. 
(I thought it would be important to mention it.)

It didn't crash at 2^30 data set but almost burned my PC, so don't do it. 
Have fun :)

4/27/2024, huge updates after I slept:

1-performance boost I changed the data structure to be a 1D array instead of 
2D array (cache utilization) Now the most important function is at (int row_i,int col_i).

2: updated the class to be working with any standard data types (template class) and non-standard 
data type (complex matrices) and their results are tested, but if there is any issue, please let me know. 
know)

3-added complex class, which performs all the essintial operations on complex numbers 

4: I didn't add complex classes for the sake of complex matrices. I'm working on adding 
fast forier transform 

5-updated transpose, dot, is_symmetric, and others to work seamlessly with both 
standard and non-standard types, all thanks to the overloaded conjugate that 
I added it so that if the passed type is standard, then it does nothing else. 
If it's complex, then it produces the conjugate. 

6. There are some new functions related to FORIER:
-forier_mat, which returns a forier matrix when passing a certain dimension
-forier_diagonal, which returns the main diagonal of forier in the form of a column matrix (I will use it in fft).
  added some functions like arrange, which arranges matrix rows at a certain sequence you pass as an input.
and returns the matrix (which will be used in FFT).
-at_quarter, which puts a matrix at the upper_left, lower_left, upper_right, and lower_right quarters of a matrix
of the caller, the passed function must be less than or equal to the quarter size of the caller matrix.
aka:: if the caller has 4x4, then the maximum size of the passed matrix is 2x2. 

7-updated other functions like fix_pivots to be more efficient in terms of memory usage and performance
Now it utilizes a simple column of sequence that is obtained from gauss_down. 

8: Any function that returns pivot indices, aka gauss_down, ref,and others, returns them in an <int> column matrix.
Also, it's optional to pass the address of a matrix if you want the extra information.

9-matrix<int> ,matrix<complex> is how you initialize a matrix, and that's probably all I have to say.

10. Feel free to use any code.

11: Now that it doesn't crash at 500x5000 matrix multiplication, I'm currently running a 
10000x10000 matrix matrix multiplication and didn't crash as I'm writing these updates.

have fun!

4/27/2024: huge updates:
until I declare it when you use the class.
just do this: matrix<data_type> mat instead of matrix
Since then, it has worked with any data type, like int, float , etc.
and now works with non-standard-type complex
Im trying to implement fast forier transform. Wish me luck. 
Also, more updates tomorrow after I go to sleep.
Have a nice day.
4/22/2024: small updates:
added cofactor, which returns a cofactor related to an element in the matrix. 
added cofactors which returns cofactors matrix 

4/18/2024: A small update:
1-added SubLambda I, which performs A-lambda *I and returns the result in a more efficient manner.
2-added eigen_vectors, which returns the eigen vectors of a system using eigen 
values passed as an input as a column matrix 
3: Announcement: We will try to add eigenvalues in the near future since
requires a lot of thought and work. I will try my best.

4/13/2024 update:
fixed an issue that affected null space calculation if pivot positions were not in the left of rref now 
works properly for both cases for [0 1] and [1 0]. It was a stupid mistake.
[0 0]   [0 0] 
4/11/2024 update:
very important!!!
1-fixed original pivot loctions recording when passing a matrix with the old_locations parameter to gauss_down 
(Also, you want the old locations of pivots during the elimination.)
to be a permutation matrix instead of recording every row exchange that happens. 
which fixes two important functions the fix_pivots, det 
For the det, it was a sign issue, but for fix_pivots, it was a big deal since it was used in the calculation of the left null space. 

4/10/2024 update:
1-added extract_col, which allows you to extract a column at an index and put it in a matrix.
2-added gram_shmidt, which returns orthonormal vectors in the form of a matrix from a bunch (matrix) of independent columns 

4/9/2024 updates: 
1-added quality functions that allow for the appending of two matrices, one for appending 
by cols and the other for appending by rows and optimizing some functions, have fun.
2-added projection, which returns the projection matrix for a system of equations.
3-added fit_least_squares, which performs a least squares fit to a given set of data points and returns the matrix.

older upadtes:
very important update: fix_pivots, which rearranges matrix rows so that rows containing pivots are 
put on top and rest at the bottom function is really essential if some functions that use gaussian 
elimination since some outputs might be wrong. I'm not going to force it, just so you know.

Gaussian elimination downward, or Gauss_down, now has an enum if you want the new pivot indices. 
You just pass a matrix, and there is no need to pass extra values. If you want the old pivot indices, then pass old_locations.
